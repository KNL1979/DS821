{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 11)\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "# Specify the path to your JSON Lines file\n",
    "file_path = 'Arxiv_data/arxiv-abstracts.jsonl.gz'\n",
    "\n",
    "# Setting seed for reproducability\n",
    "random.seed(42)\n",
    "\n",
    "# Open the gzipped JSON Lines file\n",
    "with gzip.open(file_path, 'rt', encoding='utf-8') as file:\n",
    "    # Read a random subset of lines (adjust the sample_size as needed)\n",
    "    sample_size = 500000  # Adjust this number as needed\n",
    "    data = [json.loads(line) for line in random.sample(file.readlines(), sample_size)]\n",
    "\n",
    "# Convert the list of dictionaries into a pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id         submitter  \\\n",
      "0  2008.13253      Edgar Galvan   \n",
      "1   1012.4110       Eoin Butler   \n",
      "2   0803.0691  Paul E. Gunnells   \n",
      "3  2111.01041          Tong Liu   \n",
      "4   1411.6806     Huy Pham Cong   \n",
      "\n",
      "                                             authors  \\\n",
      "0  Edgar Galv\\'an, Oxana Gorshkova, Peter Mooney,...   \n",
      "1  Gorm B. Andresen, Mohammad D. Ashkezari, Marce...   \n",
      "2                 Gautam Chinta and Paul E. Gunnells   \n",
      "3                 Shuang-Xi Yi, Mei Du, and Tong Liu   \n",
      "4                     C. Huy Pham and V. Lien Nguyen   \n",
      "\n",
      "                                               title  \\\n",
      "0  Statistical Tree-based Population Seeding for ...   \n",
      "1                    Search For Trapped Antihydrogen   \n",
      "2  Constructing Weyl group multiple Dirichlet series   \n",
      "3  Statistical analyses on the energies of X-ray ...   \n",
      "4  Tunnelling through finite graphene superlattic...   \n",
      "\n",
      "                                            comments  \\\n",
      "0                                 14 Pages, 5 Tables   \n",
      "1                                12 pages, 7 figures   \n",
      "2                   incorporates referee's revisions   \n",
      "3  13 pages, 3 figures, 3 tables, accepted for pu...   \n",
      "4                                21 pages, 6 figures   \n",
      "\n",
      "                                  journal-ref                             doi  \\\n",
      "0                                        None                            None   \n",
      "1         Physics Letters B 695 (2011) 95-104  10.1016/j.physletb.2010.11.004   \n",
      "2                                        None                            None   \n",
      "3                                        None                            None   \n",
      "4  J. Phys.: Condens. Matter 27 (2015) 095302   10.1088/0953-8984/27/9/095302   \n",
      "\n",
      "                                            abstract report-no  \\\n",
      "0    Multiple Artificial Intelligence (AI) method...      None   \n",
      "1    We present the results of an experiment to s...      None   \n",
      "2    Let Phi be a reduced root system of rank r. ...      None   \n",
      "3    Distinct X-ray plateau and flare phases have...      None   \n",
      "4    An exact expression of the transmission prob...      None   \n",
      "\n",
      "                 categories  versions  \n",
      "0                   [cs.NE]      [v1]  \n",
      "1  [physics.atom-ph hep-ex]      [v1]  \n",
      "2         [math.NT math.RT]  [v1, v2]  \n",
      "3             [astro-ph.HE]      [v1]  \n",
      "4       [cond-mat.mes-hall]  [v1, v2]  \n",
      "(14295, 11)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Set the target size in megabytes\n",
    "target_size_mb = 25\n",
    "\n",
    "# Convert megabytes to bytes\n",
    "target_size_bytes = target_size_mb * (1024 ** 2)\n",
    "\n",
    "# Get the current size of the DataFrame\n",
    "current_size_bytes = sys.getsizeof(df)\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "subset_dfs = []\n",
    "\n",
    "# Initialize a variable to keep track of the total size\n",
    "total_size_bytes = 0\n",
    "\n",
    "# Iterate through rows until the target size is reached or exceeded\n",
    "for index, row in df.iterrows():\n",
    "    # Convert the current row to a DataFrame with a single row\n",
    "    row_df = pd.DataFrame([row])\n",
    "    \n",
    "    # Check the size of the row DataFrame\n",
    "    row_size_bytes = sys.getsizeof(row_df)\n",
    "    \n",
    "    # Break the loop if adding the current row exceeds the target size\n",
    "    if total_size_bytes + row_size_bytes > target_size_bytes:\n",
    "        break\n",
    "    \n",
    "    # Append the current row DataFrame to the list\n",
    "    subset_dfs.append(row_df)\n",
    "    \n",
    "    # Update the total size\n",
    "    total_size_bytes += row_size_bytes\n",
    "\n",
    "# Concatenate the list of DataFrames into the final subset DataFrame\n",
    "subset_df = pd.concat(subset_dfs, ignore_index=True)\n",
    "\n",
    "# Display the subset DataFrame\n",
    "print(subset_df.head())\n",
    "print(subset_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset DataFrame saved to: C:\\Users\\kimlu\\3. Semester\\News and Market sentiment\\Exam\\Arxiv_data\\subset_data.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Specify the path for saving the JSON Lines file\n",
    "output_jsonl_path = 'C:\\\\Users\\\\kimlu\\\\3. Semester\\\\News and Market sentiment\\\\Exam\\\\Arxiv_data\\\\subset_data.jsonl'\n",
    "\n",
    "# Save the subset DataFrame to a JSON Lines file\n",
    "subset_df.to_json(output_jsonl_path, orient='records', lines=True)\n",
    "\n",
    "# Display the path to the saved JSON Lines file\n",
    "print(f\"Subset DataFrame saved to: {output_jsonl_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SentimentF23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
